import numpy as np
import matplotlib.pyplot as plt

x = np.array([155, 180, 164, 162, 181, 182, 173, 190, 171, 170, 181, 182, 189, 184, 209, 210])
y = np.array([51, 52, 54, 53, 55, 59, 61, 59, 63, 76, 64, 66, 69, 72, 70, 80])

x_norm = (x- x.mean()) / x.std()

theta_0 = np.random.rand()
theta_1 = np.random.rand()
learning_rate = 1e-6
print(f'theta_0 is {theta_0}, theta_1 is {theta_1}')

def h(x, theta_0, theta_1):
    return theta_0 + theta_1*x

def cost_func(x, y, theta_0, theta_1):
    m = x.shape[0]
    return (1/(2*m))*np.sum((h(x,theta_0,theta_1) - y )**2)

def grad_descent(x, y, theta_0, theta_1, learning_rate):
    m = x.shape[0]
    grad_0 = theta_0 - learning_rate * (1/m) * np.sum(h(x, theta_0, theta_1) - y)
    grad_1 = theta_1 - learning_rate * (1/m) * np.sum((h(x, theta_0, theta_1) - y)*x)
    theta_0 = grad_0
    theta_1 = grad_1
    return theta_0, theta_1
